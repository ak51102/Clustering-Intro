{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to Clustering.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyM8DwdxyY9hDKBAvA57zCkO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Clustering-Intro/blob/master/Intro_to_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63PUH_CfxRCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scikit-learn\n",
        "# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KADZWGxIyG3d",
        "colab_type": "text"
      },
      "source": [
        "Create a Synthetic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Y0BQKTx3YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# synthetic classification dataset\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# create scatter plot for samples from each class\n",
        "for class_value in range(2):\n",
        "\t# get row indexes for samples with this class\n",
        "\trow_ix = where(y == class_value)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbJI24zgyJ8S",
        "colab_type": "text"
      },
      "source": [
        "Affinity Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSTcBo5JyKGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# affinity propagation clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = AffinityPropagation(damping=0.9)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNI4P-mnz1Us",
        "colab_type": "text"
      },
      "source": [
        "Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh4wGxAez1dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# agglomerative clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = AgglomerativeClustering(n_clusters=2)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1zyBA5y0Csz",
        "colab_type": "text"
      },
      "source": [
        "BIRCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3vvoTnn0C1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "# birch clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import Birch\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = Birch(threshold=0.01, n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pFXsc-X0JD3",
        "colab_type": "text"
      },
      "source": [
        "DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkN0N0YK0H4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dbscan clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import DBSCAN\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = DBSCAN(eps=0.30, min_samples=9)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWumL07k0n_X",
        "colab_type": "text"
      },
      "source": [
        "K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddz9x6Fz0oH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "# k-means clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import KMeans\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = KMeans(n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXVchmkA0u3j",
        "colab_type": "text"
      },
      "source": [
        "Mini Batch K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGPrECAC0vBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# mini-batch k-means clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = MiniBatchKMeans(n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqm8fFlM1Qy8",
        "colab_type": "text"
      },
      "source": [
        "Mean Shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDLjtzRd1Q84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean shift clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import MeanShift\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = MeanShift()\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTj44MUu1aAY",
        "colab_type": "text"
      },
      "source": [
        "OPTICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xgG6m81aJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# optics clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import OPTICS\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = OPTICS(eps=0.8, min_samples=10)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-G6oruQ1i0B",
        "colab_type": "text"
      },
      "source": [
        "Spectral Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn4JoUS21kwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# spectral clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = SpectralClustering(n_clusters=2)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSigYEjr1qmU",
        "colab_type": "text"
      },
      "source": [
        "Gaussian Mix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2hxSK581quq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "# gaussian mixture clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = GaussianMixture(n_components=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}