{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to Clustering.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNEnHV8Ssd5PQEAqN6TwLE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Clustering-Intro/blob/master/Intro_to_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXPsVNOiYxyz",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction to Clustering**\n",
        "\n",
        "An overview of clustering techniques.\n",
        ">Affinity Propagation\n",
        "Agglomerative Clustering\n",
        "BIRCH\n",
        "DBSCAN\n",
        "K-Means\n",
        "Mini-batch K-Means\n",
        "Mean Shift\n",
        "Gaussian Mixture Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lw7hHVwZ01x",
        "colab_type": "text"
      },
      "source": [
        "Each algorithm offers a different approach to the challenge of discovering natural groups in data.\n",
        "\n",
        "There is no best clustering algorithm, and no easy way to find the best algorithm for your data without using controlled experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63PUH_CfxRCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scikit-learn\n",
        "# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYuCqMqjYbUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KADZWGxIyG3d",
        "colab_type": "text"
      },
      "source": [
        "**Create a Synthetic Dataset**<br>\n",
        "The dataset has two distinct clusters. <br>\n",
        "\n",
        "Can the clustering algorithms identifiy the two clusters?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Y0BQKTx3YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# synthetic classification dataset\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# create scatter plot for samples from each class\n",
        "for class_value in range(2):\n",
        "\t# get row indexes for samples with this class\n",
        "\trow_ix = where(y == class_value)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7_Kx0aDrekY",
        "colab_type": "text"
      },
      "source": [
        "Plot function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJhiWFWGlDOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_function(clusters, yhat,X):\n",
        "  for cluster in clusters:\n",
        "    # get row indexes for samples with this cluster\n",
        "    row_ix = where(yhat == cluster)\n",
        "    # create scatter of these samples\n",
        "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOOAwx3urE9K",
        "colab_type": "text"
      },
      "source": [
        "K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFe6jBz5rFFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k-means clustering\n",
        "from sklearn.cluster import KMeans\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = KMeans(n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHXev4eHrLnp",
        "colab_type": "text"
      },
      "source": [
        "Mini-Batch K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUe1WpClrLxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mini-batch k-means clustering\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = MiniBatchKMeans(n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_rLqtZAsC4k",
        "colab_type": "text"
      },
      "source": [
        "Gaussian Mix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAa3vonhsDCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gaussian mixture clustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = GaussianMixture(n_components=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlWA8IzlsQxR",
        "colab_type": "text"
      },
      "source": [
        "Birch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1_oi5wKsQ6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# birch clustering\n",
        "from sklearn.cluster import Birch\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = Birch(threshold=0.01, n_clusters=2)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbJI24zgyJ8S",
        "colab_type": "text"
      },
      "source": [
        "Affinity Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSTcBo5JyKGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# affinity propagation clustering\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "#1 HYPER PARAMETER TO TUNE 0.5 to 1\n",
        "#AffinityPropagation(damping=0.5, max_iter=200, convergence_iter=15, \n",
        "#copy=True, preference=None, affinity='euclidean', verbose=False)\n",
        "model = AffinityPropagation(damping=0.9, )\n",
        "\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNI4P-mnz1Us",
        "colab_type": "text"
      },
      "source": [
        "Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh4wGxAez1dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# agglomerative clustering\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = AgglomerativeClustering(n_clusters=2)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pFXsc-X0JD3",
        "colab_type": "text"
      },
      "source": [
        "DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkN0N0YK0H4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dbscan clustering\n",
        "from sklearn.cluster import DBSCAN\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = DBSCAN(eps=0.30, min_samples=9)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXVchmkA0u3j",
        "colab_type": "text"
      },
      "source": [
        "Mean Shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDLjtzRd1Q84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mean shift clustering\n",
        "from sklearn.cluster import MeanShift\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = MeanShift()\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTj44MUu1aAY",
        "colab_type": "text"
      },
      "source": [
        "OPTICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xgG6m81aJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optics clustering\n",
        "from sklearn.cluster import OPTICS\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = OPTICS(eps=0.8, min_samples=10)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-G6oruQ1i0B",
        "colab_type": "text"
      },
      "source": [
        "Spectral Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn4JoUS21kwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spectral clustering\n",
        "from sklearn.cluster import SpectralClustering\n",
        "# define dataset\n",
        "#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "# define the model\n",
        "model = SpectralClustering(n_clusters=2)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "plot_function(clusters, yhat,X)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}